{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTqzBQyKaV0K"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking, Modelling, Traning, Predict"
      ],
      "metadata": {
        "id": "_kSswyg2bOma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: CUDA not available! Will use CPU (very slow)\")\n",
        "\n",
        "# ==================== STEP 2: Dataset Analysis ====================\n",
        "def analyze_dataset(mask_dir, image_dir):\n",
        "    \"\"\"Analyze dataset to detect number of classes and mask format\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ANALYZING DATASET...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    mask_files = sorted(glob(os.path.join(mask_dir, \"*.png\")))\n",
        "    image_files = sorted(glob(os.path.join(image_dir, \"*.png\")))\n",
        "\n",
        "    print(f\"Found {len(mask_files)} mask files\")\n",
        "    print(f\"Found {len(image_files)} image files\")\n",
        "\n",
        "    if len(mask_files) == 0 or len(image_files) == 0:\n",
        "        raise ValueError(\"No images found! Check your paths.\")\n",
        "\n",
        "    # Analyze first mask\n",
        "    sample_mask = np.array(Image.open(mask_files[0]))\n",
        "    print(f\"\\nMask shape: {sample_mask.shape}\")\n",
        "    print(f\"Mask dtype: {sample_mask.dtype}\")\n",
        "\n",
        "    # Check if RGB or Grayscale\n",
        "    if len(sample_mask.shape) == 3:\n",
        "        print(f\"Mask format: RGB (channels: {sample_mask.shape[2]})\")\n",
        "        # Convert RGB to class indices if needed\n",
        "        unique_colors = np.unique(sample_mask.reshape(-1, sample_mask.shape[2]), axis=0)\n",
        "        num_classes = len(unique_colors)\n",
        "        print(f\"Unique colors found: {num_classes}\")\n",
        "        print(f\"Colors (first 10): \\n{unique_colors[:10]}\")\n",
        "        is_rgb = True\n",
        "        unique_values = None\n",
        "    else:\n",
        "        print(f\"Mask format: Grayscale\")\n",
        "        unique_values = np.unique(sample_mask)\n",
        "        num_classes = int(unique_values.max()) + 1  # Max value + 1 untuk handle semua kelas\n",
        "        print(f\"Unique values: {unique_values}\")\n",
        "        print(f\"Max class value: {unique_values.max()}\")\n",
        "        print(f\"Number of classes (max+1): {num_classes}\")\n",
        "        is_rgb = False\n",
        "\n",
        "    # Sample image\n",
        "    sample_image = np.array(Image.open(image_files[0]))\n",
        "    print(f\"\\nImage shape: {sample_image.shape}\")\n",
        "    print(f\"Image dtype: {sample_image.dtype}\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return {\n",
        "        'num_classes': num_classes,\n",
        "        'is_rgb_mask': is_rgb,\n",
        "        'mask_files': mask_files,\n",
        "        'image_files': image_files,\n",
        "        'image_shape': sample_image.shape,\n",
        "        'mask_shape': sample_mask.shape,\n",
        "        'unique_values': unique_values\n",
        "    }\n",
        "\n",
        "# ==================== STEP 3: Custom Dataset ====================\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, num_classes, is_rgb_mask=False,\n",
        "                 img_size=(256, 256), augment=False, value_map=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.num_classes = num_classes\n",
        "        self.is_rgb_mask = is_rgb_mask\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "        self.value_map = value_map  # Mapping untuk remap nilai mask\n",
        "\n",
        "        # Build color to class mapping if RGB masks\n",
        "        if is_rgb_mask:\n",
        "            self.color_map = self._build_color_map()\n",
        "\n",
        "    def _build_color_map(self):\n",
        "        \"\"\"Build mapping from RGB colors to class indices\"\"\"\n",
        "        color_map = {}\n",
        "        sample_mask = np.array(Image.open(self.mask_paths[0]))\n",
        "        unique_colors = np.unique(sample_mask.reshape(-1, sample_mask.shape[2]), axis=0)\n",
        "\n",
        "        for idx, color in enumerate(unique_colors):\n",
        "            color_map[tuple(color)] = idx\n",
        "\n",
        "        return color_map\n",
        "\n",
        "    def _rgb_to_class(self, mask):\n",
        "        \"\"\"Convert RGB mask to class indices\"\"\"\n",
        "        h, w = mask.shape[:2]\n",
        "        class_mask = np.zeros((h, w), dtype=np.int64)\n",
        "\n",
        "        for color, class_idx in self.color_map.items():\n",
        "            match = np.all(mask == color, axis=-1)\n",
        "            class_mask[match] = class_idx\n",
        "\n",
        "        return class_mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        image = image.resize(self.img_size, Image.BILINEAR)\n",
        "        image = np.array(image) / 255.0\n",
        "\n",
        "        # Load mask\n",
        "        mask = Image.open(self.mask_paths[idx])\n",
        "        mask = mask.resize(self.img_size, Image.NEAREST)\n",
        "        mask = np.array(mask)\n",
        "\n",
        "        # Convert RGB mask to class indices if needed\n",
        "        if self.is_rgb_mask:\n",
        "            mask = self._rgb_to_class(mask)\n",
        "\n",
        "        # Remap mask values if value_map is provided\n",
        "        if self.value_map is not None:\n",
        "            mask_remapped = np.zeros_like(mask)\n",
        "            for old_val, new_val in self.value_map.items():\n",
        "                mask_remapped[mask == old_val] = new_val\n",
        "            mask = mask_remapped\n",
        "\n",
        "        # Convert to tensors\n",
        "        image = torch.FloatTensor(image).permute(2, 0, 1)  # HWC to CHW\n",
        "        mask = torch.LongTensor(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# ==================== STEP 4: U-Net Architecture ====================\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.enc4 = DoubleConv(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec4 = DoubleConv(1024, 512)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = DoubleConv(512, 256)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = DoubleConv(256, 128)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "\n",
        "        # Output\n",
        "        self.out = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool(enc1))\n",
        "        enc3 = self.enc3(self.pool(enc2))\n",
        "        enc4 = self.enc4(self.pool(enc3))\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck = self.bottleneck(self.pool(enc4))\n",
        "\n",
        "        # Decoder\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat([dec4, enc4], dim=1)\n",
        "        dec4 = self.dec4(dec4)\n",
        "\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat([dec3, enc3], dim=1)\n",
        "        dec3 = self.dec3(dec3)\n",
        "\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat([dec2, enc2], dim=1)\n",
        "        dec2 = self.dec2(dec2)\n",
        "\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat([dec1, enc1], dim=1)\n",
        "        dec1 = self.dec1(dec1)\n",
        "\n",
        "        return self.out(dec1)\n",
        "\n",
        "# ==================== STEP 5: Training Functions ====================\n",
        "def train_epoch(model, loader, criterion, optimizer, device, epoch, num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_pixels = 0\n",
        "    total_pixels = 0\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    pbar = tqdm(loader, desc=f\"Epoch {epoch}/{num_epochs} [TRAIN]\")\n",
        "\n",
        "    for batch_idx, (images, masks) in enumerate(pbar):\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct_pixels += (preds == masks).sum().item()\n",
        "        total_pixels += masks.numel()\n",
        "\n",
        "        # Update progress bar\n",
        "        avg_loss = total_loss / (batch_idx + 1)\n",
        "        accuracy = 100.0 * correct_pixels / total_pixels\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{avg_loss:.4f}',\n",
        "            'acc': f'{accuracy:.2f}%'\n",
        "        })\n",
        "\n",
        "    return total_loss / len(loader), accuracy\n",
        "\n",
        "def validate(model, loader, criterion, device, epoch, num_epochs):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct_pixels = 0\n",
        "    total_pixels = 0\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    pbar = tqdm(loader, desc=f\"Epoch {epoch}/{num_epochs} [VAL]  \")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, masks) in enumerate(pbar):\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct_pixels += (preds == masks).sum().item()\n",
        "            total_pixels += masks.numel()\n",
        "\n",
        "            # Update progress bar\n",
        "            avg_loss = total_loss / (batch_idx + 1)\n",
        "            accuracy = 100.0 * correct_pixels / total_pixels\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{avg_loss:.4f}',\n",
        "                'acc': f'{accuracy:.2f}%'\n",
        "            })\n",
        "\n",
        "    return total_loss / len(loader), accuracy\n",
        "\n",
        "def calculate_iou(pred, target, num_classes):\n",
        "    \"\"\"Calculate Intersection over Union (IoU)\"\"\"\n",
        "    ious = []\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "\n",
        "    for cls in range(num_classes):\n",
        "        pred_cls = (pred == cls)\n",
        "        target_cls = (target == cls)\n",
        "\n",
        "        intersection = (pred_cls & target_cls).sum().float()\n",
        "        union = (pred_cls | target_cls).sum().float()\n",
        "\n",
        "        if union == 0:\n",
        "            iou = float('nan')\n",
        "        else:\n",
        "            iou = intersection / union\n",
        "\n",
        "        ious.append(iou.item())\n",
        "\n",
        "    return np.nanmean(ious)\n",
        "\n",
        "# ==================== STEP 6: Visualization ====================\n",
        "def visualize_predictions(model, dataset, device, num_samples=4):\n",
        "    \"\"\"Visualize model predictions\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 4))\n",
        "\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, idx in enumerate(indices):\n",
        "            image, mask = dataset[idx]\n",
        "\n",
        "            # Predict\n",
        "            image_input = image.unsqueeze(0).to(device)\n",
        "            output = model(image_input)\n",
        "            pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "            # Denormalize image for display\n",
        "            image_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "            mask_np = mask.cpu().numpy()\n",
        "\n",
        "            # Plot\n",
        "            axes[i, 0].imshow(image_np)\n",
        "            axes[i, 0].set_title('Original Image')\n",
        "            axes[i, 0].axis('off')\n",
        "\n",
        "            axes[i, 1].imshow(mask_np, cmap='tab20')\n",
        "            axes[i, 1].set_title('Ground Truth')\n",
        "            axes[i, 1].axis('off')\n",
        "\n",
        "            axes[i, 2].imshow(pred, cmap='tab20')\n",
        "            axes[i, 2].set_title('Prediction')\n",
        "            axes[i, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('predictions.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# ==================== STEP 7: MAIN EXECUTION ====================\n",
        "def main():\n",
        "    global device\n",
        "    # Enable CUDA debugging\n",
        "    import os\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "    # Clear CUDA cache to recover from previous errors\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"üîÑ Cleared CUDA cache\\n\")\n",
        "\n",
        "    # CONFIGURE THESE PATHS\n",
        "    MASK_DIR = \"/content/drive/MyDrive/datasets/masks\"  # Path to mask folder\n",
        "    IMAGE_DIR = \"/content/drive/MyDrive/datasets/images\"  # Path to image folder\n",
        "\n",
        "    # Hyperparameters\n",
        "    IMG_SIZE = (256, 256)\n",
        "    BATCH_SIZE = 8\n",
        "    NUM_EPOCHS = 50\n",
        "    LEARNING_RATE = 1e-4\n",
        "\n",
        "    # Step 1: Analyze dataset\n",
        "    info = analyze_dataset(MASK_DIR, IMAGE_DIR)\n",
        "    num_classes = info['num_classes']\n",
        "    is_rgb_mask = info['is_rgb_mask']\n",
        "\n",
        "    print(f\"\\nDetected {num_classes} classes\")\n",
        "    print(f\"Mask format: {'RGB' if is_rgb_mask else 'Grayscale'}\")\n",
        "\n",
        "    # Create value mapping for grayscale masks\n",
        "    value_map = None\n",
        "    if info['unique_values'] is not None:\n",
        "        unique_vals = info['unique_values']\n",
        "        print(f\"Unique mask values: {unique_vals}\")\n",
        "\n",
        "        # Remap to continuous values 0, 1, 2, ..., n-1\n",
        "        value_map = {int(old_val): new_val for new_val, old_val in enumerate(unique_vals)}\n",
        "        num_classes = len(unique_vals)  # Use actual number of unique values\n",
        "\n",
        "        print(f\"\\nRemapping mask values:\")\n",
        "        for old_val, new_val in value_map.items():\n",
        "            print(f\"  {old_val} -> {new_val}\")\n",
        "        print(f\"\\nFinal number of classes: {num_classes}\")\n",
        "\n",
        "    # Step 2: Split dataset\n",
        "    train_imgs, val_imgs, train_masks, val_masks = train_test_split(\n",
        "        info['image_files'],\n",
        "        info['mask_files'],\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTrain samples: {len(train_imgs)}\")\n",
        "    print(f\"Validation samples: {len(val_imgs)}\")\n",
        "\n",
        "    # Step 3: Create datasets\n",
        "    train_dataset = SegmentationDataset(\n",
        "        train_imgs, train_masks, num_classes, is_rgb_mask, IMG_SIZE, augment=True, value_map=value_map\n",
        "    )\n",
        "    val_dataset = SegmentationDataset(\n",
        "        val_imgs, val_masks, num_classes, is_rgb_mask, IMG_SIZE, augment=False, value_map=value_map\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    # VERIFY: Check remapped mask values\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"VERIFYING REMAPPED MASKS...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Check first sample\n",
        "    sample_img, sample_mask = train_dataset[0]\n",
        "    unique_remapped = torch.unique(sample_mask)\n",
        "    print(f\"Sample mask shape: {sample_mask.shape}\")\n",
        "    print(f\"Unique values after remapping: {unique_remapped.numpy()}\")\n",
        "    print(f\"Min value: {sample_mask.min().item()}, Max value: {sample_mask.max().item()}\")\n",
        "\n",
        "    # Check ALL masks in dataset\n",
        "    print(\"\\nChecking all masks in training set...\")\n",
        "    all_valid = True\n",
        "    for i in range(len(train_dataset)):\n",
        "        _, mask = train_dataset[i]\n",
        "        if mask.max().item() >= num_classes or mask.min().item() < 0:\n",
        "            print(f\"‚ö†Ô∏è  Invalid mask at index {i}: min={mask.min().item()}, max={mask.max().item()}\")\n",
        "            all_valid = False\n",
        "            if i > 10:  # Stop after 10 errors\n",
        "                break\n",
        "\n",
        "    if not all_valid:\n",
        "        print(\"\\n‚ö†Ô∏è  ERROR: Some masks have invalid values!\")\n",
        "        return\n",
        "    else:\n",
        "        print(f\"‚úì All {len(train_dataset)} training masks are valid (0 to {num_classes-1})\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 4: Initialize model\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"INITIALIZING MODEL...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Try CUDA first, fallback to CPU if error\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()  # Wait for previous operations\n",
        "            torch.cuda.empty_cache()  # Clear cache\n",
        "\n",
        "        model = UNet(in_channels=3, num_classes=num_classes)\n",
        "\n",
        "        # Move to device with error handling\n",
        "        try:\n",
        "            model = model.to(device)\n",
        "            print(f\"‚úì Model successfully moved to {device}\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"‚ö†Ô∏è  CUDA Error: {e}\")\n",
        "            print(\"üîÑ Falling back to CPU...\")\n",
        "            device_fallback = torch.device('cpu')\n",
        "            model = model.to(device_fallback)\n",
        "            print(f\"‚úì Model running on CPU\")\n",
        "            # Update device for rest of training\n",
        "            device = device_fallback\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "        print(f\"Model initialized with {num_classes} classes\")\n",
        "        print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Fatal error during model initialization: {e}\")\n",
        "        print(\"\\nüí° SOLUTION: Go to Runtime ‚Üí Restart Runtime and run again\")\n",
        "        return\n",
        "\n",
        "    # Test forward pass with dummy data\n",
        "    print(\"\\nTesting forward pass...\")\n",
        "    try:\n",
        "        dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
        "        dummy_output = model(dummy_input)\n",
        "        print(f\"‚úì Forward pass successful! Output shape: {dummy_output.shape}\")\n",
        "\n",
        "        # Test loss calculation\n",
        "        dummy_target = torch.randint(0, num_classes, (1, 256, 256)).to(device)\n",
        "        dummy_loss = criterion(dummy_output, dummy_target)\n",
        "        print(f\"‚úì Loss calculation successful! Loss: {dummy_loss.item():.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error during forward pass: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 5: Training loop\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"STARTING TRAINING...\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "    print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "    print(f\"Image Size: {IMG_SIZE}\")\n",
        "    print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(\n",
        "            model, train_loader, criterion, optimizer, device, epoch+1, NUM_EPOCHS\n",
        "        )\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc = validate(\n",
        "            model, val_loader, criterion, device, epoch+1, NUM_EPOCHS\n",
        "        )\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        elapsed_time = time.time() - start_time\n",
        "        eta = (elapsed_time / (epoch + 1)) * (NUM_EPOCHS - epoch - 1)\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Summary:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
        "        print(f\"  Time: {epoch_time:.1f}s | Elapsed: {elapsed_time/60:.1f}m | ETA: {eta/60:.1f}m\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_unet_model.pth')\n",
        "            print(f\"  ‚úì Best model saved! (Val Loss: {best_val_loss:.4f}, Val Acc: {best_val_acc:.2f}%)‡§µ‡§∞‡•Å‡§®)\")\n",
        "\n",
        "        # GPU Memory usage\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"  GPU Memory: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
        "\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nüéâ Training completed in {total_time/60:.1f} minutes!\")\n",
        "    print(f\"Best Val Loss: {best_val_loss:.4f}\")\n",
        "    print(f\"Best Val Acc: {best_val_acc:.2f}%\")\n",
        "\n",
        "    # Step 6: Plot training history\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss', marker='o', markersize=3)\n",
        "    plt.plot(val_losses, label='Val Loss', marker='s', markersize=3)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training & Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accs, label='Train Acc', marker='o', markersize=3)\n",
        "    plt.plot(val_accs, label='Val Acc', marker='s', markersize=3)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training & Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Step 7: Visualize predictions\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"GENERATING PREDICTIONS...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    model.load_state_dict(torch.load('best_unet_model.pth'))\n",
        "    visualize_predictions(model, val_dataset, device, num_samples=4)\n",
        "\n",
        "    # Step 8: Calculate IoU\n",
        "    model.eval()\n",
        "    total_iou = 0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            total_iou += calculate_iou(preds, masks, num_classes)\n",
        "\n",
        "    mean_iou = total_iou / len(val_loader)\n",
        "    print(f\"\\nMean IoU: {mean_iou:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"TRAINING COMPLETED!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Best model saved as: best_unet_model.pth\")\n",
        "    print(f\"Training history saved as: training_history.png\")\n",
        "    print(f\"Predictions saved as: predictions.png\")\n",
        "\n",
        "# ==================== STEP 8: PREDICTION FUNCTION ====================\n",
        "def predict_single_image(model_path, image_path, num_classes, device):\n",
        "    \"\"\"Predict on a single image\"\"\"\n",
        "    # Load model\n",
        "    model = UNet(in_channels=3, num_classes=num_classes).to(device)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    # Load and preprocess image\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    original_size = image.size\n",
        "    image = image.resize((256, 256), Image.BILINEAR)\n",
        "    image_np = np.array(image) / 255.0\n",
        "    image_tensor = torch.FloatTensor(image_np).permute(2, 0, 1).unsqueeze(0).to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # Resize prediction back to original size\n",
        "    pred_resized = cv2.resize(pred.astype(np.uint8), original_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    axes[0].imshow(Image.open(image_path))\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(pred_resized, cmap='tab20')\n",
        "    axes[1].set_title('Prediction')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return pred_resized\n",
        "\n",
        "# RUN TRAINING\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "    # EXAMPLE: Predict on new image\n",
        "    # pred = predict_single_image(\n",
        "    #     model_path='best_unet_model.pth',\n",
        "    #     image_path='path/to/test/image.png',\n",
        "    #     num_classes=YOUR_NUM_CLASSES,\n",
        "    #     device=device\n",
        "    # )"
      ],
      "metadata": {
        "id": "X1phFF8YamcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CEK CLASSES"
      ],
      "metadata": {
        "id": "XMluOWh0bk9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Untuk mendapatkan berapa total class\n",
        "import torch\n",
        "\n",
        "def detect_num_classes(model_path):\n",
        "    \"\"\"Auto-detect number of classes from saved model\"\"\"\n",
        "\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"üîç DETECTING NUMBER OF CLASSES\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Model: {model_path}\\n\")\n",
        "\n",
        "    # Load state dict\n",
        "    state_dict = torch.load(model_path, map_location='cpu')\n",
        "\n",
        "    # Get output layer shape\n",
        "    out_weight_shape = state_dict['out.weight'].shape\n",
        "    num_classes = out_weight_shape[0]  # First dimension = number of classes\n",
        "\n",
        "    print(f\"‚úÖ Detected: {num_classes} classes\")\n",
        "    print(f\"   Output layer shape: {out_weight_shape}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return num_classes\n",
        "\n",
        "# ========== USAGE ==========\n",
        "MODEL_PATH = '/content/best_unet_model.pth'\n",
        "\n",
        "# Auto-detect\n",
        "NUM_CLASSES = detect_num_classes(MODEL_PATH)\n",
        "\n",
        "print(f\"‚ú® Use this value for prediction:\")\n",
        "print(f\"   NUM_CLASSES = {NUM_CLASSES}\")"
      ],
      "metadata": {
        "id": "24ZPmENmbnQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict\n"
      ],
      "metadata": {
        "id": "m57bwmthbdpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ==================== U-Net Model ====================\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.enc4 = DoubleConv(256, 512)\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec4 = DoubleConv(1024, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = DoubleConv(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = DoubleConv(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "        self.out = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool(enc1))\n",
        "        enc3 = self.enc3(self.pool(enc2))\n",
        "        enc4 = self.enc4(self.pool(enc3))\n",
        "        bottleneck = self.bottleneck(self.pool(enc4))\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat([dec4, enc4], dim=1)\n",
        "        dec4 = self.dec4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat([dec3, enc3], dim=1)\n",
        "        dec3 = self.dec3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat([dec2, enc2], dim=1)\n",
        "        dec2 = self.dec2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat([dec1, enc1], dim=1)\n",
        "        dec1 = self.dec1(dec1)\n",
        "        return self.out(dec1)\n",
        "\n",
        "# ==================== AUTO-DETECT NUM_CLASSES ====================\n",
        "def detect_num_classes(model_path):\n",
        "    \"\"\"Auto-detect number of classes from saved model\"\"\"\n",
        "    state_dict = torch.load(model_path, map_location='cpu')\n",
        "    num_classes = state_dict['out.weight'].shape[0]\n",
        "    return num_classes\n",
        "\n",
        "# ==================== PREDICT FUNCTION ====================\n",
        "def predict_image(model_path, image_path, num_classes=None):\n",
        "    \"\"\"Prediksi segmentasi pada gambar\"\"\"\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Auto-detect num_classes if not provided\n",
        "    if num_classes is None:\n",
        "        print(\"üîç Auto-detecting number of classes...\")\n",
        "        num_classes = detect_num_classes(model_path)\n",
        "        print(f\"‚úÖ Detected: {num_classes} classes\\n\")\n",
        "\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"üîÆ PREDICTION MODE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Model: {model_path}\")\n",
        "    print(f\"Image: {image_path}\")\n",
        "    print(f\"Classes: {num_classes}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Load model\n",
        "    print(\"üì¶ Loading model...\")\n",
        "    model = UNet(in_channels=3, num_classes=num_classes).to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    print(\"‚úÖ Model loaded!\\n\")\n",
        "\n",
        "    # Load image\n",
        "    print(\"üñºÔ∏è  Loading image...\")\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    original_size = image.size\n",
        "    print(f\"Original size: {original_size[0]}x{original_size[1]}\")\n",
        "\n",
        "    # Preprocess\n",
        "    image_resized = image.resize((256, 256), Image.BILINEAR)\n",
        "    image_np = np.array(image_resized) / 255.0\n",
        "    image_tensor = torch.FloatTensor(image_np).permute(2, 0, 1).unsqueeze(0).to(device)\n",
        "\n",
        "    # Predict\n",
        "    print(\"üöÄ Running inference...\")\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # Resize back to original\n",
        "    pred_resized = cv2.resize(pred.astype(np.uint8), original_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    unique_classes = np.unique(pred_resized)\n",
        "    print(f\"‚úÖ Prediction completed!\")\n",
        "    print(f\"Detected classes in image: {unique_classes}\")\n",
        "    print(f\"Output shape: {pred_resized.shape}\\n\")\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Original\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title('Original Image', fontsize=16, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Prediction\n",
        "    im = axes[1].imshow(pred_resized, cmap='tab20', vmin=0, vmax=num_classes-1)\n",
        "    axes[1].set_title('Prediction Mask', fontsize=16, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Add colorbar for mask\n",
        "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "    divider = make_axes_locatable(axes[1])\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    cbar = plt.colorbar(im, cax=cax)\n",
        "    cbar.set_label('Class ID', fontsize=12)\n",
        "\n",
        "    # Overlay\n",
        "    overlay = np.array(image).copy()\n",
        "    mask_colored = plt.cm.tab20(pred_resized / max(num_classes-1, 1))[:, :, :3]\n",
        "    overlay = (overlay * 0.5 + mask_colored * 255 * 0.5).astype(np.uint8)\n",
        "    axes[2].imshow(overlay)\n",
        "    axes[2].set_title('Overlay (Original + Mask)', fontsize=16, fontweight='bold')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('prediction_result.png', dpi=150, bbox_inches='tight')\n",
        "    print(f\"üíæ Result saved to: prediction_result.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Statistics\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üìä PREDICTION STATISTICS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for class_id in range(num_classes):\n",
        "        pixels = np.sum(pred_resized == class_id)\n",
        "        percentage = (pixels / pred_resized.size) * 100\n",
        "        if pixels > 0:  # Only show classes that appear\n",
        "            print(f\"Class {class_id:2d}: {pixels:8,} pixels ({percentage:6.2f}%)\")\n",
        "\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"‚ú® DONE!\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return pred_resized\n",
        "\n",
        "\n",
        "# ==================== KONFIGURASI ====================\n",
        "# üëá GANTI 2 HAL INI SAJA (NUM_CLASSES otomatis terdeteksi):\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/best_unet_model.pth'                                 # Path ke model .pth\n",
        "IMAGE_PATH = '/content/drive/MyDrive/download (1).jpg'   # Path ke gambar\n",
        "\n",
        "# ==================== RUN PREDICTION ====================\n",
        "# NUM_CLASSES akan otomatis terdeteksi dari model!\n",
        "prediction = predict_image(MODEL_PATH, IMAGE_PATH)"
      ],
      "metadata": {
        "id": "bjZPN0m2apIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}